{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "def load_yolo_model(model_name: str = 'yolov5x') -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Load the YOLOv5 model from Ultralytics' PyTorch Hub.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): The model variant to load. Default is 'yolov5x'.\n",
    "    \n",
    "    Returns:\n",
    "        torch.nn.Module: The YOLOv5 model.\n",
    "    \"\"\"\n",
    "    return torch.hub.load('ultralytics/yolov5', model_name)\n",
    "\n",
    "def process_video(video_path: str, output_path: str, resize_factor: float = 0.5) -> None:\n",
    "    \"\"\"\n",
    "    Process a video to detect cars using YOLOv5 and save the output with annotations.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        output_path (str): Path to save the output video file.\n",
    "        resize_factor (float): Factor to resize the video. Default is 0.5.\n",
    "    \"\"\"\n",
    "    # Load YOLOv5 model\n",
    "    model = load_yolo_model()\n",
    "    \n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
    "\n",
    "    # Get original dimensions\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_width = int(original_width * resize_factor)\n",
    "    new_height = int(original_height * resize_factor)\n",
    "    \n",
    "    # Get the original frame rate of the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n",
    "    \n",
    "    # Class index for cars in COCO dataset (YOLOv5 uses this)\n",
    "    car_class_index = 2\n",
    "    \n",
    "    # Calculate the time between frames\n",
    "    frame_time = 1.0 / fps\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Resize the frame\n",
    "        frame_resized = cv2.resize(frame, (new_width, new_height))\n",
    "        \n",
    "        # Perform inference\n",
    "        results = model(frame_resized)\n",
    "        \n",
    "        # Extract detections\n",
    "        detections = results.xyxy[0].cpu().numpy()\n",
    "        annotated_frame = frame_resized.copy()\n",
    "        \n",
    "        # Filter for cars only\n",
    "        for detection in detections:\n",
    "            x1, y1, x2, y2, conf, cls = detection\n",
    "            if int(cls) == car_class_index:\n",
    "                cv2.rectangle(annotated_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                cv2.putText(annotated_frame, f'Car {conf:.2f}', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Car Detection', annotated_frame)\n",
    "        \n",
    "        # Write the frame to output video\n",
    "        out.write(annotated_frame)\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Wait to synchronize with the video frame rate\n",
    "        if elapsed_time < frame_time:\n",
    "            time.sleep(frame_time - elapsed_time)\n",
    "        \n",
    "        # Exit on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_video_path = '4K Road traffic video for object detection and tracking - free download now! [MNn9qKG2UFI].webm'\n",
    "    output_video_path = 'car_detection_objects.avi'\n",
    "    process_video(input_video_path, output_video_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
